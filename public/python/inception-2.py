# -*- coding: utf-8 -*-
"""Inception

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hpzzQ11hRTWGFfr598Fifg45wiqvTCfB
"""

import os
import tensorflow as tf
import numpy as np
import pickle

path = os.path.join(os.path.dirname(__file__), "../assets/Dataset.Resize.Pad.4")

SEED = 99

# Training, Validasi dan Testing => 70% : 10% : 20%
train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(
    path,
    label_mode="categorical",
    image_size=(299, 299),
    subset="both",
    validation_split=0.3,
    seed=SEED,
)

val_batches = tf.data.experimental.cardinality(val_ds)

test_ds = val_ds.take((2 * val_batches) // 3)
val_ds = val_ds.take((2 * val_batches) // 3)

# Training = train_y
train_y = []

for i, label in train_ds:
    for y in label:
        train_y.append(y.numpy())

np.unique(train_y, return_counts=True)

# Validasi = val_y

val_y = []


for i, label in val_ds:
    for y in label:
        val_y.append(y.numpy())

np.unique(val_y, return_counts=True)

# Testing = test_y

test_y = []

for i, label in test_ds:
    for y in label:
        test_y.append(y.numpy())

np.unique(test_y, return_counts=True)

model = tf.keras.applications.inception_v3.InceptionV3(
    include_top=True, weights=None, classes=4
)

model.compile(
    optimizer="adam",
    loss=tf.keras.losses.categorical_crossentropy,
    metrics=["accuracy"],
)

callback = tf.keras.callbacks.EarlyStopping(
    monitor="val_loss", patience=5, start_from_epoch=0
)

history = model.fit(train_ds, epochs=1, validation_data=val_ds, callbacks=[callback])

with open("inceptionv3.pkl", "wb") as f:
    pickle.dump(history, f)
